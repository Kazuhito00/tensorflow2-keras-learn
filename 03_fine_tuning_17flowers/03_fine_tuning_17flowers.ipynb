{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17flowersデータセットのダウンロード\n",
    "urllib.request.urlretrieve(\n",
    "    'http://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz',\n",
    "    '17flowers.tgz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17flowersデータセットの解凍\n",
    "with tarfile.open('17flowers.tgz') as tar:\n",
    "    tar.extractall()\n",
    "os.rename('jpg', '17flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17flowersデータセットのラベルを定義\n",
    "labels = ['Tulip', 'Snowdrop', 'LilyValley', 'Bluebell', 'Crocus', \n",
    "          'Iris', 'Tigerlily', 'Daffodil', 'Fritillary', 'Sunflower', \n",
    "          'Daisy', 'ColtsFoot', 'Dandelion', 'Cowslip', 'Buttercup', \n",
    "          'Windflower', 'Pansy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validationディレクトリパス準備\n",
    "train_dir = os.path.join(os.getcwd(), '17flowers', 'train')\n",
    "validation_dir = os.path.join(os.getcwd(), '17flowers', 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validationに各ラベルのディレクトリを準備\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "for directory_name in labels:\n",
    "    os.mkdir(os.path.join(os.getcwd(), '17flowers', 'train', directory_name))\n",
    "    os.mkdir(os.path.join(os.getcwd(), '17flowers', 'validation', directory_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validationにデータセットを配置\n",
    "dataset_number = 80\n",
    "train_ratio = 0.75\n",
    "train_number = int(dataset_number * train_ratio)\n",
    "\n",
    "jpg_files = [f for f in sorted(os.listdir('17flowers')) if f.endswith('.jpg')]\n",
    "for index, jpg_file in enumerate(jpg_files):\n",
    "    if (index % dataset_number) < train_number:\n",
    "        destination_directory = 'train'\n",
    "    else:\n",
    "        destination_directory = 'validation'\n",
    "        \n",
    "    src = os.path.join(os.getcwd(), '17flowers', jpg_file)\n",
    "    dst = os.path.join(os.getcwd(), '17flowers', destination_directory, labels[index // dataset_number])\n",
    "    shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validation配下のjpgファイル一覧を取得\n",
    "train_files = glob.glob(os.path.join(train_dir, '*', '*.jpg'))\n",
    "validation_files = glob.glob(os.path.join(validation_dir, '*', '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16モデルをロード(include_top=False:ネットワークの出力層側にある全結合層を含まない)\n",
    "vgg16_base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル可視化\n",
    "vgg16_base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15層までを固定し再学習しないよう設定\n",
    "for layer in vgg16_base_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "for layer in vgg16_base_model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力用の全結合層を再定義しモデルを構築\n",
    "x = tf.keras.layers.Flatten()(vgg16_base_model.output)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(17, activation='softmax', name='last_output')(x)\n",
    "vgg16_model = tf.keras.Model(inputs=vgg16_base_model.inputs, outputs=output, name='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル(転移学習、ファインチューニングの場合はAdamよりSGDが良いケースが多い)\n",
    "vgg16_model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル可視化\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validation用のImageDataGeneratorを定義(データ拡張をする場合はコメントアウトを解除する)\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                           # width_shift_range=2,\n",
    "                                           # height_shift_range=2,\n",
    "                                           # brightness_range=(0.8, 1.2),\n",
    "                                           # channel_shift_range=0.2,\n",
    "                                           # zoom_range=0.02,\n",
    "                                           # rotation_range=2\n",
    "                                          )\n",
    "validation_image_generator = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGeneratorを用いてディレクトリからデータを読み込む準備\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           classes=labels,\n",
    "                                                           class_mode='categorical')\n",
    "validation_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              classes=labels,\n",
    "                                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック(1エポック毎)\n",
    "checkpoint_path = os.path.join(os.getcwd(), 'checkpoints', 'weights.{epoch:03d}-{val_loss:.3f}-{val_accuracy:.3f}.hdf5')\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 verbose=1, \n",
    "                                                 save_best_only=True,\n",
    "                                                 mode='auto',\n",
    "                                                 save_weights_only=False, \n",
    "                                                 save_freq='epoch')\n",
    "\n",
    "# 評価値の改善が見られない場合に学習率を減らすコールバックを定義\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5,\n",
    "                                          verbose=1, mode='auto', min_delta=0.0001,\n",
    "                                          cooldown=3, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "with tf.device(\"CPU:0\"): # CUDA、cuDNNが正しくインストールされている場合はwith句を外す\n",
    "    history = vgg16_model.fit(\n",
    "        train_data_gen,\n",
    "        steps_per_epoch=len(train_files) // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_data_gen,\n",
    "        validation_steps=len(validation_files) // batch_size,\n",
    "        callbacks=[cp_callback, lr_callback]\n",
    "        # callbacks=[cp_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "load_model = tf.keras.models.load_model(\"checkpoints/weights.***-****-****.hdf5\") # 出来上がったcheckpointファイルを指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト画像を1枚ロード\n",
    "from IPython.display import Image, display_png\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img('17flowers/validation/Sunflower/image_0781.jpg', False, target_size=(224, 224))\n",
    "display_png(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力画像成形、および正規化\n",
    "x = img_to_array(img)\n",
    "x = x.reshape(-1, 224, 224, 3)\n",
    "x = x.astype('float32')\n",
    "x /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論実行\n",
    "with tf.device(\"CPU:0\"): # CUDA、cuDNNが正しくインストールされている場合はwith句を外す\n",
    "    predict_result = load_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論結果表示\n",
    "print(predict_result)\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))\n",
    "print(labels[np.argmax(np.squeeze(predict_result))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2_00",
   "language": "python",
   "name": "tensorflow_2_00"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
