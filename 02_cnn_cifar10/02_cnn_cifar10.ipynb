{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cifar10データロード\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN構築\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        24, 3, activation='relu', padding='same',\n",
    "        input_shape=(32, 32, 3)),  # (32, 32, 24)\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),  # (30, 30, 32)\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'), # (15, 15, 32)\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),  # (15, 15, 64)\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),  # (13, 13, 64)\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'), # (6, 6, 64)\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 24)        672       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        6944      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 640,042\n",
      "Trainable params: 640,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデル可視化\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    '02_cnn_cifar10.hdf5', verbose=1, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "49760/50000 [============================>.] - ETA: 0s - loss: 1.9413 - accuracy: 0.2957\n",
      "Epoch 00001: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 16s 310us/sample - loss: 1.9393 - accuracy: 0.2965 - val_loss: 1.4235 - val_accuracy: 0.5214\n",
      "Epoch 2/15\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 1.3870 - accuracy: 0.5367\n",
      "Epoch 00002: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 13s 252us/sample - loss: 1.3863 - accuracy: 0.5370 - val_loss: 1.2867 - val_accuracy: 0.5779\n",
      "Epoch 3/15\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 1.2406 - accuracy: 0.5924\n",
      "Epoch 00003: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 13s 253us/sample - loss: 1.2407 - accuracy: 0.5927 - val_loss: 1.1161 - val_accuracy: 0.6339\n",
      "Epoch 4/15\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 1.1462 - accuracy: 0.6253\n",
      "Epoch 00004: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 13s 256us/sample - loss: 1.1461 - accuracy: 0.6253 - val_loss: 1.0481 - val_accuracy: 0.6630\n",
      "Epoch 5/15\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.9789 - accuracy: 0.6627\n",
      "Epoch 00005: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 13s 270us/sample - loss: 0.9784 - accuracy: 0.6629 - val_loss: 0.8483 - val_accuracy: 0.7069\n",
      "Epoch 6/15\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.8908 - accuracy: 0.6907\n",
      "Epoch 00006: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 14s 276us/sample - loss: 0.8907 - accuracy: 0.6908 - val_loss: 0.7970 - val_accuracy: 0.7240\n",
      "Epoch 7/15\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.8475 - accuracy: 0.7040\n",
      "Epoch 00007: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 15s 296us/sample - loss: 0.8478 - accuracy: 0.7038 - val_loss: 0.7908 - val_accuracy: 0.7294\n",
      "Epoch 8/15\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.8160 - accuracy: 0.7169\n",
      "Epoch 00008: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 14s 280us/sample - loss: 0.8160 - accuracy: 0.7169 - val_loss: 0.8512 - val_accuracy: 0.7114\n",
      "Epoch 9/15\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.7971 - accuracy: 0.7220\n",
      "Epoch 00009: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 14s 270us/sample - loss: 0.7972 - accuracy: 0.7220 - val_loss: 0.7480 - val_accuracy: 0.7395\n",
      "Epoch 10/15\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.7724 - accuracy: 0.7291\n",
      "Epoch 00010: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.7721 - accuracy: 0.7292 - val_loss: 0.7382 - val_accuracy: 0.7401\n",
      "Epoch 11/15\n",
      "49888/50000 [============================>.] - ETA: 0s - loss: 0.7468 - accuracy: 0.7386\n",
      "Epoch 00011: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 13s 265us/sample - loss: 0.7470 - accuracy: 0.7385 - val_loss: 0.7497 - val_accuracy: 0.7461\n",
      "Epoch 12/15\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.7353 - accuracy: 0.7432\n",
      "Epoch 00012: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 14s 273us/sample - loss: 0.7352 - accuracy: 0.7433 - val_loss: 0.7916 - val_accuracy: 0.7318\n",
      "Epoch 13/15\n",
      "49824/50000 [============================>.] - ETA: 0s - loss: 0.7172 - accuracy: 0.7506\n",
      "Epoch 00013: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 14s 271us/sample - loss: 0.7175 - accuracy: 0.7505 - val_loss: 0.6834 - val_accuracy: 0.7677\n",
      "Epoch 14/15\n",
      "49856/50000 [============================>.] - ETA: 0s - loss: 0.7070 - accuracy: 0.7524\n",
      "Epoch 00014: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.7073 - accuracy: 0.7523 - val_loss: 0.6888 - val_accuracy: 0.7617\n",
      "Epoch 15/15\n",
      "49952/50000 [============================>.] - ETA: 0s - loss: 0.6906 - accuracy: 0.7597\n",
      "Epoch 00015: saving model to 02_cnn_cifar10.hdf5\n",
      "50000/50000 [==============================] - 13s 265us/sample - loss: 0.6908 - accuracy: 0.7597 - val_loss: 0.7033 - val_accuracy: 0.7567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26a7b52a6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=15,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "load_model = tf.keras.models.load_model(\"02_cnn_cifar10.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト画像を1枚ロード\n",
    "from IPython.display import Image, display_png\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img('image/automobile10.png', False, target_size=(32, 32))\n",
    "display_png(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力画像成形、および正規化\n",
    "x = img_to_array(img)\n",
    "x = x.reshape(-1, 32, 32, 3)\n",
    "x = x.astype('float32')\n",
    "x /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論実行\n",
    "predict_result = load_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_result)\n",
    "print(np.squeeze(predict_result)) # 不要な次元を削除\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2_00",
   "language": "python",
   "name": "tensorflow_2_00"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
